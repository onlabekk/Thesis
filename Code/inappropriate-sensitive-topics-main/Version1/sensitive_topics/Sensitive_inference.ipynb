{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Sensitive_inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai3tzEXzHhxJ"
      },
      "source": [
        "#Installing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kiYhxW9R6Kg2"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install deeppavlov\n",
        "!python -m deeppavlov install squad_bert\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow-gpu==1.15.2\n",
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tybdG56xkO7k"
      },
      "source": [
        "Make sure that tf can see gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLkiuW7B6Kg3",
        "outputId": "286f13d1-a3bb-4258-b55b-20d0be0c66cf"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(\"=\"*100)\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "print(\"=\"*100)\n",
        "from tensorflow.python.client import device_lib\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "get_available_gpus()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "====================================================================================================\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11169264157387939262\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14674281152\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 18235363450799666721\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2xr_Cl0HRv7"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDSYpgeH6Kg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c1ab6a6-2a1b-4403-9da5-02891b3790cf"
      },
      "source": [
        "from deeppavlov.core.data.utils import download\n",
        "from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader\n",
        "from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator\n",
        "\n",
        "from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor\n",
        "from deeppavlov.models.preprocessors.torch_transformers_preprocessor import TorchTransformersPreprocessor\n",
        "\n",
        "from deeppavlov.core.data.simple_vocab import SimpleVocabulary\n",
        "from deeppavlov.models.preprocessors.one_hotter import OneHotter\n",
        "from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n",
        "from deeppavlov.models.bert.bert_classifier import BertClassifierModel\n",
        "from deeppavlov.metrics.accuracy import sets_accuracy\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "prob2labels = Proba2Labels(max_proba=True)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGsfNOEVHuk1"
      },
      "source": [
        "# Prepare models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TaQPm3QeOJc"
      },
      "source": [
        "The model is stored [here](https://drive.google.com/file/d/1u_g7CSJPYUHuRc6CaoLn1tKhJ6t8kQxF/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZxZdEAeNS-"
      },
      "source": [
        "wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1u_g7CSJPYUHuRc6CaoLn1tKhJ6t8kQxF' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1u_g7CSJPYUHuRc6CaoLn1tKhJ6t8kQxF\" -O sensitive_model && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRk3kB3atDpH"
      },
      "source": [
        "!unzip sensitive_model.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB3zfrMC6Kg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38a260c-03fa-427b-a3db-17d9c74234ef"
      },
      "source": [
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/ru_conversational_cased_L-12_H-768_A-12.tar.gz\n",
        "!tar -xf ru_conversational_cased_L-12_H-768_A-12.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-05 08:25:01--  http://files.deeppavlov.ai/deeppavlov_data/bert/ru_conversational_cased_L-12_H-768_A-12.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://files.deeppavlov.ai/deeppavlov_data/bert/ru_conversational_cased_L-12_H-768_A-12.tar.gz [following]\n",
            "--2021-03-05 08:25:02--  https://files.deeppavlov.ai/deeppavlov_data/bert/ru_conversational_cased_L-12_H-768_A-12.tar.gz\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 660061308 (629M) [application/octet-stream]\n",
            "Saving to: ‘ru_conversational_cased_L-12_H-768_A-12.tar.gz’\n",
            "\n",
            "ru_conversational_c 100%[===================>] 629.48M  2.61MB/s    in 2m 49s  \n",
            "\n",
            "2021-03-05 08:27:52 (3.72 MB/s) - ‘ru_conversational_cased_L-12_H-768_A-12.tar.gz’ saved [660061308/660061308]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uufHYmDY6Kg7"
      },
      "source": [
        "PRETR_BERT_PATH = \"./ru_conversational_cased_L-12_H-768_A-12\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oJlMOzv6Kg7"
      },
      "source": [
        "bert_preprocessor = BertPreprocessor(vocab_file=os.path.join(PRETR_BERT_PATH,\"vocab.txt\"),\n",
        "                                     do_lower_case=False,\n",
        "                                     max_seq_length=256)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlzIVXKisCW"
      },
      "source": [
        "import json\r\n",
        "with open(\"target_vaiables_id2topic_dict.json\",\"r\") as f:\r\n",
        "  target_vaiables_id2topic_dict = json.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciXUbqMN6Kg9",
        "outputId": "6d51ff04-1e13-4a37-d827-327267e4219e"
      },
      "source": [
        "bert_classifier = BertClassifierModel(\n",
        "    multilabel = True,\n",
        "    n_classes=391,\n",
        "    return_probas=True,\n",
        "    one_hot_labels=True,\n",
        "    bert_config_file=os.path.join(PRETR_BERT_PATH,\"bert_config.json\"),\n",
        "    pretrained_bert=os.path.join(PRETR_BERT_PATH,\"bert_model.ckpt\"),\n",
        "    save_path=\"sensitive_model_v1/model\",\n",
        "    load_path=\"sensitive_model_v1/model\",\n",
        "    keep_prob=0.5,\n",
        "    learning_rate=1e-05,\n",
        "    learning_rate_drop_patience=5,\n",
        "    learning_rate_drop_div=2.0\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:92: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:161: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:97: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-03-05 08:39:12.622 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /content/sensitive_model_v1/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/sensitive_model_v1/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKf1KNfYkWlE"
      },
      "source": [
        "# Perform predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du3Mwy_0PpAF",
        "outputId": "d3dd1dff-ff01-43ce-b97d-e50c83baf0b5"
      },
      "source": [
        "def adjust_multilabel_predictions(y):\r\n",
        "    named_predicitons = []   \r\n",
        "    for y_c in y:\r\n",
        "      y_c = target_vaiables_id2topic_dict[str(np.argmax(y_c))]\r\n",
        "      named_predicitons.append(y_c)\r\n",
        "    return named_predicitons\r\n",
        "\r\n",
        "text = [\"люблю качать фильмы с торрентов\", \"это какая-то порнография\"]\r\n",
        "y_valid_pred = adjust_multilabel_predictions(bert_classifier(bert_preprocessor(text)))\r\n",
        "y_valid_pred"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['online_crime', 'pornography']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}